# -*- coding: utf-8 -*-
"""testing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r5Mpr2dovewlm6vJXrjVvGEwVPrRPt3x
"""

# Liberías
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Test Normalidad
from scipy.stats import shapiro
from scipy.stats import kstest
from scipy.stats import anderson
from scipy.stats import jarque_bera
from scipy.stats import normaltest

# Test heterocedasticidad
# Test independencia

# Clases test

class Test:
  def __init__(self, data):
    self.data = data

  def shapiro_wilk(self, columna, alpha = 0.05):
    '''Pequeñas o medianas (max 50 - 200). Alta potencia en pequeñas,
    demasiado sensible en muestras grandes, detectará mínimas desviaciones irrelevantes para el análisis'''
    stat, p_value = shapiro(self.data[columna])
    resultados = pd.DataFrame({'stat': stat, 'p_value':p_value, 'alpha': alpha}, index=['Shapiro-Wilk'])
    if p_value < alpha:
      print("La muestra NO proviene de una población normalmente distribuida")
    else:
      print("La muestra SÍ proviene de una población normalmente distribuida")
    return resultados

  def kolmogorov_smirnov(self, columna, alpha = 0.05):
    '''Útil para muestras medianas y grandes. Aunque es genérico, funciona mejor cuando la media y desviación estándar de la población son conocidas'''
    stat, p_value = kstest(self.data[columna], 'norm')
    resultados = pd.DataFrame({'stat': stat, 'p_value':p_value, 'alpha': alpha}, index=['Kolmogorov-Smirnov'])
    if p_value < alpha:
      print("La muestra NO proviene de una población normalmente distribuida")
    else:
      print("La muestra SÍ proviene de una población normalmente distribuida")
    return resultados

  def anderson_darling(self, columna):
    '''Es una variación del test de Kolmogorov-Smirnov, que otorga más peso a las colas de la distribución, lo que la hace más sensible a los datos en los extremos.
    Adecuado para muestras de tamaño mediano. Ideal cuando se desea observar el ajuste de los datos en las colas.
    Más sensible que el test de Kolmogorov-Smirnov, especialmente para detectar valores atípicos en los extremos de la distribución.
    Puede ser excesivamente sensible a pequeños desajustes en las colas.'''
    result = anderson(self.data[columna], 'norm')
    stat = result.statistic
    critical_values = result.critical_values
    significance_levels = result.significance_level
    resultados = pd.DataFrame({'stat': result.statistic,
                               'critical_values': result.critical_values,
                               'significance_levels': result.significance_level},
                              columns=['stat', 'critical_values', 'significance_levels'])
    return resultados

  def jarque_bera(self, columna, alpha = 0.05):
    '''Este test evalúa la normalidad en función de la curtosis y la asimetría de los datos.
    Se basa en la idea de que en una distribución normal, la asimetría es cercana a cero y la curtosis es cercana a 3.
    Funciona mejor con muestras grandes y cuando estás interesado en validar la normalidad de la distribución en términos de asimetría y curtosis.
    Es Fácil de interpretar y centrado en la forma de la distribución. Poco adecuado para muestras pequeñas o medianas, ya que pierde poder estadístico en esas situaciones.'''
    stat, p_value = jarque_bera(self.data[columna])
    resultados = pd.DataFrame({'stat': stat, 'p_value':p_value, 'alpha': alpha}, index=['Jarque-Bera'])
    if p_value < alpha:
      print("La muestra NO proviene de una población normalmente distribuida")
    else:
      print("La muestra SÍ proviene de una población normalmente distribuida")
    return resultados

  def dagostino_pearson(self, columna, alpha = 0.05):
    '''Similar al test de Jarque-Bera, evalúa asimetría y curtosis, combinándolas en una estadística para verificar si los datos son normales.
    Recomendado para muestras medianas a grandes y cuando buscas validar tanto la simetría como el aplanamiento de la distribución.
    Más poderoso que el Jarque-Bera para muestras grandes, detectando desviaciones en ambos parámetros. Menos efectivo en muestras pequeñas y puede ser sensible a valores extremos.'''
    stat, p_value = normaltest(self.data[columna])
    resultados = pd.DataFrame({'stat': stat, 'p_value':p_value, 'alpha': alpha}, index=['Jarque-Bera'])
    if p_value < alpha:
      print("La muestra NO proviene de una población normalmente distribuida")
    else:
      print("La muestra SÍ proviene de una población normalmente distribuida")
    return resultados

    ''' Lilliefors, asume media y varianza poblacional son desconocidas, alternativa a shapiro cuando el tamaño de muestra es superior a 50'''